

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Setting up Pubmed Parser with PySpark &mdash; Pubmed Parser 0.5.2.dev6+g6aa8a17 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=c33b2ab7"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Resources" href="resources.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Pubmed Parser
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Resources</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Setting up Pubmed Parser with PySpark</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pubmed Parser</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Setting up Pubmed Parser with PySpark</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/spark.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="setting-up-pubmed-parser-with-pyspark">
<h1>Setting up Pubmed Parser with PySpark<a class="headerlink" href="#setting-up-pubmed-parser-with-pyspark" title="Link to this heading">ÔÉÅ</a></h1>
<p>Below, we put a small snippet to setup <code class="docutils literal notranslate"><span class="pre">Spark</span> <span class="pre">2.1</span></code> on Jupyter Notebook.
We can use PySpark as a workflow to process MEDLINE XML data to Spark dataframe.
Using PySpark can reduce parsing time of more than 25 million documents to less than 10 minutes when you have multiple core processors.</p>
<p><strong>Note</strong> that the <code class="docutils literal notranslate"><span class="pre">spark_home</span></code> path to downloaded Spark might be different.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">findspark</span>
<span class="n">findspark</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">spark_home</span><span class="o">=</span><span class="s2">&quot;/opt/spark-2.1.0-bin-cdh5.9.0/&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In Spark 2.1, <code class="docutils literal notranslate"><span class="pre">spark</span></code> in this case can use as <code class="docutils literal notranslate"><span class="pre">sparkContext</span></code> which has access to <code class="docutils literal notranslate"><span class="pre">parallelize</span></code> or <code class="docutils literal notranslate"><span class="pre">createDataFrame</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">pyspark.conf</span> <span class="kn">import</span> <span class="n">SparkConf</span>

<span class="n">conf</span> <span class="o">=</span> <span class="n">SparkConf</span><span class="p">()</span><span class="o">.</span>\
    <span class="n">setAppName</span><span class="p">(</span><span class="s1">&#39;map&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="n">setMaster</span><span class="p">(</span><span class="s1">&#39;local[5]&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;spark.yarn.appMasterEnv.PYSPARK_PYTHON&#39;</span><span class="p">,</span> <span class="s1">&#39;~/anaconda3/bin/python&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON&#39;</span><span class="p">,</span> <span class="s1">&#39;~/anaconda3/bin/python&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;executor.memory&#39;</span><span class="p">,</span> <span class="s1">&#39;8g&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;spark.yarn.executor.memoryOverhead&#39;</span><span class="p">,</span> <span class="s1">&#39;16g&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;spark.sql.codegen&#39;</span><span class="p">,</span> <span class="s1">&#39;true&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;spark.yarn.executor.memory&#39;</span><span class="p">,</span> <span class="s1">&#39;16g&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;yarn.scheduler.minimum-allocation-mb&#39;</span><span class="p">,</span> <span class="s1">&#39;500m&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;spark.dynamicAllocation.maxExecutors&#39;</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">)</span><span class="o">.</span>\
    <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;spark.driver.maxResultSize&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span>\
    <span class="n">appName</span><span class="p">(</span><span class="s2">&quot;testing&quot;</span><span class="p">)</span><span class="o">.</span>\
    <span class="n">config</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span><span class="o">.</span>\
    <span class="n">getOrCreate</span><span class="p">()</span>
</pre></div>
</div>
<p>Please see the full implementation details in <a class="reference external" href="https://github.com/titipata/pubmed_parser/tree/master/scripts">scripts</a> folder on the repository.</p>
<p>We will update the documentation on how to incorporate Pubmed Parser with <a class="reference external" href="https://dask.org/">dask</a> soon.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="resources.html" class="btn btn-neutral float-left" title="Resources" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Titipat Achakulvisut.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>